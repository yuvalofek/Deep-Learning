# Deep_Learning


Differentiable directed acyclic graphs covering applications in unsupervised learning, as well as generative and discriminative modeling. 
Gradient-based methods for optimization (stochastic gradient descent, Nesterov momentum, adam). Fast gradient computation for arbitrary 
computational graphs (automatic differentiation). Exploding and vanishing gradient problems. Convolutional networks. Arbitrary graphs for
regression, classification and ranking. Autoencoders, adversarial networks and variations for unsupervised representation learning, 
generative modeling and other applications. Focus on applications in computer vision, speech processing and research problems in
communication theory.
